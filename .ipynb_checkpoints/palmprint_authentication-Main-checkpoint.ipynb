{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ec0a16-b4bc-4dde-baa7-5a032c492c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy matplotlib seaborn opencv-python pillow tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31dedd04-7e15-4953-abda-07c4e6acebce",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import cv2\n",
    "\n",
    "import sys\n",
    "\n",
    "import os\n",
    "\n",
    "import re\n",
    "\n",
    "from PIL import Image \n",
    "import PIL\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import tensorflow dependencies - Functional API\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "# Import metric calculations\n",
    "from tensorflow.keras.metrics import Precision, Recall , Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46b52128",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#function for viewing the image \n",
    "def show_img(path,title = 'Default Text'):\n",
    "\n",
    "    plt.imshow(path,cmap = 'gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(title,{'fontsize': 20}, y = -0.13)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20313776",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "input_path = 'img.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3a8d88d",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file 'img.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m show_img(\u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal Image\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\pyplot.py:2404\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   2400\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimread)\n\u001b[0;32m   2401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(\n\u001b[0;32m   2402\u001b[0m         fname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath \u001b[38;5;241m|\u001b[39m BinaryIO, \u001b[38;5;28mformat\u001b[39m: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2403\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\image.py:1525\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parse\u001b[38;5;241m.\u001b[39murlparse(fname)\u001b[38;5;241m.\u001b[39mscheme) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1519\u001b[0m     \u001b[38;5;66;03m# Pillow doesn't handle URLs directly.\u001b[39;00m\n\u001b[0;32m   1520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1521\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease open the URL for reading and pass the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult to Pillow, e.g. with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1523\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1524\u001b[0m         )\n\u001b[1;32m-> 1525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimg_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[0;32m   1526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[0;32m   1527\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL\u001b[38;5;241m.\u001b[39mPngImagePlugin\u001b[38;5;241m.\u001b[39mPngImageFile) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m   1528\u001b[0m             pil_to_array(image))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py:3309\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3307\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[0;32m   3308\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[1;32m-> 3309\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m: cannot identify image file 'img.jpg'"
     ]
    }
   ],
   "source": [
    "show_img(plt.imread(input_path),'Original Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54887849",
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# returning the maximum array among the given array\n",
    "\n",
    "def maxSize(lst) :\n",
    "    size = []\n",
    "    for arr in lst:\n",
    "        x,y,z = arr.shape\n",
    "        size.append(x)\n",
    "    maxpos = size.index(max(size))\n",
    "    return(lst[maxpos])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e0d3be",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def diff_find(array):\n",
    "    j=0\n",
    "    s1 = []\n",
    "    while j <len(array):\n",
    "        e1=array[j][0]\n",
    "        e2=array[j][1]\n",
    "        while j<len(array)-1 and (array[j+1][0] - array[j][0]) < 30  :\n",
    "            e1 = (e1 + array[j+1][0])/2\n",
    "            e2 = (e2 + array[j+1][1])/2\n",
    "            j=j+1\n",
    "        s1.append([e1,e2])\n",
    "        j=j+1\n",
    "    return s1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fbc5c5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def find_angle(p1,p2,p3):\n",
    "    a = np.array(p1)\n",
    "    b = np.array(p2)\n",
    "    c = np.array(p3)\n",
    "    \n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    \n",
    "    d = np.cross(ba,bc)\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    \n",
    "\n",
    "    return (np.degrees(angle)) if d <0 else -(np.degrees(angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5fe3bd",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def vally_points(input_path):\n",
    "    original_img = cv2.imread(input_path)\n",
    "#     print(original_img.shape)     # (2040, 2040, 3)\n",
    "    \n",
    "    \n",
    "    height ,  width , layer  = original_img.shape\n",
    "\n",
    "    # zero padding \n",
    "    img0 = np.zeros((height+160, width+160 , layer),np.uint8)\n",
    "\n",
    "    img0[80:-80,80:-80] = original_img\n",
    "\n",
    "    #convert colours from RGB to gray  \n",
    "    img = cv2.cvtColor(img0 , cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # smoothing the image\n",
    "    blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "\n",
    "    #extract hand by gray scale threshold\n",
    "    # In Otsu Thresholding, a value of the threshold isnâ€™t chosen but is determined automatically.\n",
    "    _, th = cv2.threshold(blur , 0 ,255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "     #use opencv moments to find out the centre of hand(x_c, y_c)\n",
    "    M = cv2.moments(th)\n",
    "    h,w = img.shape\n",
    "    x_c = M['m10']//M['m00']\n",
    "    y_c = M['m01']//M['m00']\n",
    "\n",
    "\n",
    "    # set kernel and use erosion to find hand boundary \n",
    "    kernel = np.array([[0,1,0],\n",
    "                      [1,1,1],\n",
    "                      [0,1,0]]).astype(np.uint8)\n",
    "    erosion = cv2.erode(th,kernel, iterations = 1)\n",
    "    boundary= th - erosion\n",
    "\n",
    "    cnt, _  = cv2.findContours(boundary,cv2.RETR_TREE ,cv2.CHAIN_APPROX_NONE )\n",
    "\n",
    "\n",
    "    img_c = cv2.cvtColor(img , cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # find the longest contour\n",
    "\n",
    "    cnt_ = maxSize(cnt)\n",
    "\n",
    "\n",
    "    #draw the contour\n",
    "    img_cnt = cv2.drawContours(img_c, [cnt_], 0, (255,0,0), 2)\n",
    "\n",
    "\n",
    "    # find the distance between contour and the centre\n",
    "    cnt_1 = cnt_.reshape(-1,2)\n",
    "    left_id = np.argmin(cnt_1.sum(-1))\n",
    "    cnt_2 = np.concatenate([cnt_1[left_id: , : ], cnt_1[: left_id , : ]])\n",
    "    dist_c = np. sqrt (np.square(cnt_2-[x_c , y_c]).sum(-1))\n",
    "    f = np.fft.rfft(dist_c)\n",
    "\n",
    "    # smoothing the distribution graph\n",
    "    cutoff = 15\n",
    "    f_new = np.concatenate([f[: cutoff ], 0*f[cutoff:]])\n",
    "    dist_c_1 = np.fft.irfft(f_new)\n",
    "\n",
    "    # find the derivatives and the minimas(valley of hand)\n",
    "    derivative = np.diff(dist_c_1)\n",
    "    sign_change = np.diff(np.sign(derivative))/2\n",
    "    minimas = cnt_2[np.where(sign_change>0)[0]]\n",
    "    \n",
    "    minimas = np.array(sorted(minimas, key=lambda x: x[0]))\n",
    "    return minimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1b68d9",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def roi(input_path):\n",
    "\n",
    "    original_img = cv2.imread(input_path)\n",
    "    # show_img(original_img)\n",
    "    # print(original_img.shape)     # (2040, 2040, 3)\n",
    "\n",
    "    height ,  width , layer  = original_img.shape\n",
    "\n",
    "    # zero padding \n",
    "    img0 = np.zeros((height+160, width+160 , layer),np.uint8)\n",
    "\n",
    "    img0[80:-80,80:-80] = original_img\n",
    "\n",
    "\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     plt.subplot(121)\n",
    "#     show_img(img0 , 'Image Padding')\n",
    "\n",
    "    #convert colours from RGB to gray  \n",
    "    img = cv2.cvtColor(img0 , cv2.COLOR_RGB2GRAY)\n",
    "#     show_img(img, 'Gray Scale Image')\n",
    "\n",
    "\n",
    "\n",
    "    # smoothing the image\n",
    "    blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "#     plt.subplot(122)\n",
    "#     show_img(blur , 'Smoothing the Image')\n",
    "\n",
    "    #extract hand by gray scale threshold\n",
    "    # In Otsu Thresholding, a value of the threshold isnâ€™t chosen but is determined automatically.\n",
    "    _, th = cv2.threshold(blur , 0 ,255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "    #use opencv moments to find out the centre of hand(x_c, y_c)\n",
    "    M = cv2.moments(th)\n",
    "    h,w = img.shape\n",
    "    x_c = M['m10']//M['m00']\n",
    "    y_c = M['m01']//M['m00']\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     plt.subplot(121)\n",
    "#     plt.plot(x_c , y_c , 'ro' , markersize = 6)\n",
    "#     show_img(th , 'Centre of Hand')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # set kernel and use erosion to find hand boundary \n",
    "    kernel = np.array([[0,1,0],\n",
    "                      [1,1,1],\n",
    "                      [0,1,0]]).astype(np.uint8)\n",
    "    erosion = cv2.erode(th,kernel, iterations = 1)\n",
    "    boundary= th - erosion\n",
    "\n",
    "    cnt, _  = cv2.findContours(boundary,cv2.RETR_TREE ,cv2.CHAIN_APPROX_NONE )\n",
    "    img_c = cv2.cvtColor(img , cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # find the longest contour\n",
    "    cnt_ = maxSize(cnt)\n",
    "\n",
    "\n",
    "    #draw the contour\n",
    "    img_cnt = cv2.drawContours(img_c, [cnt_], 0, (255,0,0), 5)\n",
    "\n",
    "\n",
    "    minimas = vally_points(input_path)\n",
    "#     plt.figure(figsize = (15,5))\n",
    "#     plt.subplot(131)\n",
    "#     plt.plot(minimas[0][0],minimas[0][1], color='lime', marker='o')\n",
    "#     plt.plot(minimas[1][0],minimas[1][1], color='cyan', marker='o')\n",
    "    \n",
    "#     plt.plot(minimas[2][0],minimas[2][1], color='pink', marker='o')\n",
    "#     plt.plot(minimas[3][0],minimas[3][1], color='maroon', marker='o')\n",
    "#     plt.plot(minimas[4][0],minimas[4][1], color='orange', marker='o')\n",
    "#     plt.plot(minimas[5][0],minimas[5][1], color='m', marker='o')\n",
    "#     show_img(img, 'Valley Points')\n",
    "    \n",
    "    minimas = [[i[0] , i[1]] for i in minimas if i[1]<y_c-50]\n",
    "    \n",
    "    # extracting the hull(tip) points of hand\n",
    "    hull = cv2.convexHull(cnt_)\n",
    "    cv2.drawContours(img_c, [hull], -1, (0, 0, 255), 5)\n",
    "\n",
    "    hull = [hull[i][0] for i in range(len(hull)) if  hull[i][0][1]<y_c+200]\n",
    "    hull = np.array(sorted(hull, key=lambda x: x[0]))\n",
    "    hull = np.array(diff_find(hull))\n",
    "    hull = np.array(sorted(hull, key=lambda x: x[1]))\n",
    "    \n",
    "\n",
    "#     plt.scatter(hull[0,0],hull[0,1],color='b')\n",
    "#     plt.scatter(x_c,y_c,color='r')\n",
    "#     show_img(img,'middle finger tip')\n",
    "    v1=[]\n",
    "    v2=[]\n",
    "    for i in range(len(minimas)):\n",
    "            if (find_angle(minimas[i],[x_c,y_c],hull[0])<0 and find_angle(minimas[i],[x_c,y_c],hull[0])>-65) :\n",
    "                v1.append(minimas[i])\n",
    "#                 print(find_angle(minimas[i],[x_c,y_c],hull[0]))   \n",
    "#                 plt.figure(figsize = (15,5))\n",
    "#                 plt.plot(minimas[i][0],minimas[i][1], color='pink', marker='o')\n",
    "#                 plt.scatter(hull[0,0],hull[0,1],color='b')\n",
    "#                 plt.plot(x_c , y_c , 'ro' , markersize = 10)\n",
    "#                 plt.plot([x_c,hull[0,0]],[y_c,hull[0,1]],color='#7FFF00')    \n",
    "#                 plt.plot([x_c,minimas[i][0]],[y_c,minimas[i][1]],color='#FFF68F')\n",
    "#                 show_img(img, 'Valley Points')\n",
    "\n",
    "    for i in range(len(minimas)):\n",
    "            if (find_angle(minimas[i],[x_c,y_c],hull[0])>0 and find_angle(minimas[i],[x_c,y_c],hull[0])<35):\n",
    "                v2.append(minimas[i])\n",
    "#                 print(find_angle(minimas[i],[x_c,y_c],hull[0]),minimas[i])    \n",
    "#                 plt.figure(figsize = (15,5))\n",
    "#                 plt.plot(minimas[i][0],minimas[i][1], color='pink', marker='o')\n",
    "#                 plt.scatter(hull[0,0],hull[0,1],color='b')\n",
    "#                 plt.plot(x_c , y_c , 'ro' , markersize = 10)\n",
    "#                 plt.plot([x_c,hull[0,0]],[y_c,hull[0,1]],color='#7FFF00')    \n",
    "#                 plt.plot([x_c,minimas[i][0]],[y_c,minimas[i][1]],color='#FFF68F')\n",
    "#                 show_img(img, 'Valley Points')\n",
    "                \n",
    "    v1 = np.array(sorted(v1, key=lambda x: x[0]))\n",
    "    v2 = np.array(sorted(v2, key=lambda x: x[0]))\n",
    "    v1=v1[0]\n",
    "    v2=v2[0]\n",
    "\n",
    "    \n",
    "    \n",
    "#     plt.figure(figsize = (15,5))\n",
    "#     plt.plot(v1[0],v1[1], color='pink', marker='o')\n",
    "#     plt.scatter(hull[0,0],hull[0,1],color='b')\n",
    "#     plt.plot(x_c , y_c , 'ro' , markersize = 10)\n",
    "#     plt.plot([x_c,hull[0,0]],[y_c,hull[0,1]],color='#7FFF00')    \n",
    "#     plt.plot([x_c,v1[0]],[y_c,v1[1]],color='#FFF68F')\n",
    "#     show_img(img, 'Valley Points')\n",
    "\n",
    "    \n",
    "    \n",
    "#     plt.figure(figsize = (15,5))\n",
    "#     plt.plot(v2[0],v2[1], color='pink', marker='o')\n",
    "#     plt.scatter(hull[0,0],hull[0,1],color='b')\n",
    "#     plt.plot(x_c , y_c , 'ro' , markersize = 10)\n",
    "#     plt.plot([x_c,hull[0,0]],[y_c,hull[0,1]],color='#7FFF00')    \n",
    "#     plt.plot([x_c,v2[0]],[y_c,v2[1]],color='#FFF68F')\n",
    "#     show_img(img, 'Valley Points')\n",
    "\n",
    "    theta = np.arctan2((v2-v1)[1], (v2-v1)[0])*180/np.pi\n",
    "#     print('The rotation of ROI is {:.02f}\\u00b0'.format(theta))\n",
    "    \n",
    "    p_ = int(v2[0]), int(v2[1])\n",
    "    R = cv2.getRotationMatrix2D(tuple(p_), theta, 1)\n",
    "    img_r = cv2.warpAffine(img0, R, (w,h))\n",
    "    v1 = (R[ : , : 2] @ v1 + R[ :, -1]).astype(int)\n",
    "    v2 = (R[ : , : 2] @ v2 + R[ :, -1]).astype(int)\n",
    "#     plt.figure(figsize = (15,5))\n",
    "#     plt.subplot(131)\n",
    "#     plt.plot(v1[0], v1[1], 'ro')\n",
    "#     plt.plot(v2[0], v2[1], 'bo')\n",
    "#     show_img( img_r , 'Image Rotation' )\n",
    "    \n",
    "    \n",
    "    ux = v1[0]\n",
    "    uy = v1[1] + (v2-v1)[0]//3\n",
    "    lx = v2[0]\n",
    "    ly = v2[1] + 4*(v2-v1)[0]//3\n",
    "    cv2.rectangle(img_r, (lx,ly), (ux,uy), (0,255,0), 5)\n",
    "\n",
    "\n",
    "\n",
    "    roi = img_r[uy:ly , ux:lx]\n",
    "#     plt.figure(figsize=(5,5))\n",
    "#     show_img(roi,'Location of ROI')\n",
    "    return np.array(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4329aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(img):\n",
    "    \n",
    "    # Preprocessing steps - resizing the image to be 128x128\n",
    "    img = cv2.resize(img,(128,128))\n",
    "    # Scale image to be between 0 and 1 \n",
    "    img = img / 255.0\n",
    "\n",
    "    # Return image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df92fea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c898a1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba2014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaborfilter():\n",
    "    # This function is designed to produce a set of GaborFilters \n",
    "    # an even distribution of theta values equally distributed amongst pi rad / 180 degree\n",
    "     \n",
    "    filters = []\n",
    "    num_filters = 16\n",
    "    ksize = 35  # The local area to evaluate\n",
    "    sigma = 3.0  # Larger Values produce more edges\n",
    "    lambd = 10.0\n",
    "    gamma = 0.5\n",
    "    psi = 0  # Offset value - lower generates cleaner results\n",
    "    for theta in np.arange(0, np.pi, np.pi / num_filters):  # Theta is the orientation for edge detection\n",
    "        kern = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi, ktype=cv2.CV_64F)\n",
    "        kern /= 1.0 * kern.sum()  # Brightness normalization\n",
    "        filters.append(kern)\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c144316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(img, filters):\n",
    "# This general function is designed to apply filters to our image\n",
    "     \n",
    "    # First create a numpy array the same size as our input image\n",
    "    newimage = np.zeros_like(img)\n",
    "     \n",
    "    # Starting with a blank image, we loop through the images and apply our Gabor Filter\n",
    "    # On each iteration, we take the highest value (super impose), until we have the max value across all filters\n",
    "    # The final image is returned\n",
    "    depth = -1 # remain depth same as original image\n",
    "     \n",
    "    for kern in filters:  # Loop through the kernels in our GaborFilter\n",
    "        image_filter = cv2.filter2D(img, depth, kern)  #Apply filter to image\n",
    "         \n",
    "        # Using Numpy.maximum to compare our filter and cumulative image, taking the higher value (max)\n",
    "        np.maximum(newimage, image_filter, newimage)\n",
    "    return newimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00968484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showimage(myimage, figsize=[10,10]):\n",
    "    if (myimage.ndim>2):  #This only applies to RGB or RGBA images (e.g. not to Black and White images)\n",
    "        myimage = myimage[:,:,::-1] #OpenCV follows BGR order, while matplotlib likely follows RGB order\n",
    "         \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(myimage, cmap = 'gray', interpolation = 'bicubic')\n",
    "    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad7aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hull[:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da24c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(hull[:,0,0],hull[:,0,1],s=50,edgecolors='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2c2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi1(input_path):\n",
    "\n",
    "    original_img = plt.imread(input_path)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    \n",
    "    show_img(original_img,'Original Image')\n",
    "    print(original_img.shape)     # (2040, 2040, 3)\n",
    "\n",
    "    height ,  width , layer  = original_img.shape\n",
    "\n",
    "    # zero padding \n",
    "    img0 = np.zeros((height+160, width+160 , layer),np.uint8)\n",
    "\n",
    "    img0[80:-80,80:-80] = original_img\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    \n",
    "    show_img(img0 , 'Image Padding')\n",
    "    plt.show()\n",
    "\n",
    "    #convert colours from RGB to gray  \n",
    "    img = cv2.cvtColor(img0 , cv2.COLOR_RGB2GRAY)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    \n",
    "    show_img(img, 'Gray Scale Image')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # smoothing the image\n",
    "    blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    \n",
    "   \n",
    "    show_img(blur , 'Smoothing the Image')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    #extract hand by gray scale threshold\n",
    "    # In Otsu Thresholding, a value of the threshold isnâ€™t chosen but is determined automatically.\n",
    "    _, th = cv2.threshold(blur , 0 ,255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "    #use opencv moments to find out the centre of hand(x_c, y_c)\n",
    "    M = cv2.moments(th)\n",
    "    h,w = img.shape\n",
    "    x_c = M['m10']//M['m00']\n",
    "    y_c = M['m01']//M['m00']\n",
    "    plt.figure(figsize=(20,10))\n",
    "   \n",
    "    plt.plot(x_c , y_c , 'ro' ,markersize = 10)\n",
    "    show_img(th , 'Centre of Hand')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # set kernel and use erosion to find hand boundary \n",
    "    kernel = np.array([[0,1,0],\n",
    "                      [1,1,1],\n",
    "                      [0,1,0]]).astype(np.uint8)\n",
    "    erosion = cv2.erode(th,kernel, iterations = 1)\n",
    "    boundary= th - erosion\n",
    "\n",
    "    cnt, _  = cv2.findContours(boundary,cv2.RETR_TREE ,cv2.CHAIN_APPROX_NONE )\n",
    "    img_c = cv2.cvtColor(img , cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # find the longest contour\n",
    "    cnt_ = maxSize(cnt)\n",
    "\n",
    "\n",
    "    # draw the contour\n",
    "    img_cnt = cv2.drawContours(img_c, [cnt_], 0, (255,0,0), 5)\n",
    "\n",
    "\n",
    "    minimas = vally_points(input_path)\n",
    "    plt.figure(figsize=(20,10))\n",
    "\n",
    "    plt.plot(minimas[0][0],minimas[0][1], color='lime', marker='o',markersize = 10)\n",
    "    plt.plot(minimas[1][0],minimas[1][1], color='cyan', marker='o',markersize = 10)\n",
    "    \n",
    "    plt.plot(minimas[2][0],minimas[2][1], color='pink', marker='o',markersize = 10)\n",
    "    plt.plot(minimas[3][0],minimas[3][1], color='maroon', marker='o',markersize = 10)\n",
    "    plt.plot(minimas[4][0],minimas[4][1], color='orange', marker='o',markersize = 10)\n",
    "    plt.plot(minimas[5][0],minimas[5][1], color='m', marker='o',markersize = 10)\n",
    "    show_img(img, 'All Valley Points')\n",
    "    plt.show()\n",
    "    \n",
    "    minimas = [[i[0] , i[1]] for i in minimas if i[1]<y_c-50]\n",
    "    \n",
    "    # extracting the hull(tip) points of hand\n",
    "    hull = cv2.convexHull(cnt_)\n",
    "    cv2.drawContours(img_c, [hull], -1, (0, 0, 255), 5)\n",
    "#     plt.scatter(hull[:,0],hull[:,1],color='b')\n",
    "    \n",
    "    plt.figure(figsize = (20,10))\n",
    "    plt.scatter(hull[:,0,0],hull[:,0,1],color='c',s=60,edgecolors='k')\n",
    "    show_img(img,'Finger Tips')\n",
    "\n",
    "    hull = [hull[i][0] for i in range(len(hull)) if  hull[i][0][1]<y_c+200]\n",
    "    hull = np.array(sorted(hull, key=lambda x: x[0]))\n",
    "    hull = np.array(diff_find(hull))\n",
    "    hull = np.array(sorted(hull, key=lambda x: x[1]))\n",
    "    \n",
    "    plt.figure(figsize = (20,10))\n",
    "\n",
    "    plt.scatter(hull[0,0],hull[0,1],color='c',s=70)\n",
    "    plt.scatter(x_c,y_c,color='r',s=70)\n",
    "    plt.plot([x_c,hull[0,0]],[y_c,hull[0,1]],color='blue')    \n",
    "    \n",
    "    show_img(img,'Middle Finger Tip')\n",
    "    v1=[]\n",
    "    v2=[]\n",
    "    for i in range(len(minimas)):\n",
    "            if (find_angle(minimas[i],[x_c,y_c],hull[0])<0 and find_angle(minimas[i],[x_c,y_c],hull[0])>-65) :\n",
    "                v1.append(minimas[i])\n",
    "#                 print(find_angle(minimas[i],[x_c,y_c],hull[0]))   \n",
    "#                 plt.figure(figsize = (15,5))\n",
    "#                 plt.plot(minimas[i][0],minimas[i][1], color='pink', marker='o')\n",
    "#                 plt.scatter(hull[0,0],hull[0,1],color='b')\n",
    "#                 plt.plot(x_c , y_c , 'ro' , markersize = 10)\n",
    "#                 plt.plot([x_c,hull[0,0]],[y_c,hull[0,1]],color='#7FFF00')    \n",
    "#                 plt.plot([x_c,minimas[i][0]],[y_c,minimas[i][1]],color='#FFF68F')\n",
    "#                 show_img(img, 'Valley Points')\n",
    "\n",
    "    for i in range(len(minimas)):\n",
    "            if (find_angle(minimas[i],[x_c,y_c],hull[0])>0 and find_angle(minimas[i],[x_c,y_c],hull[0])<35):\n",
    "                v2.append(minimas[i])\n",
    "#                 print(find_angle(minimas[i],[x_c,y_c],hull[0]),minimas[i])    \n",
    "#                 plt.figure(figsize = (15,5))\n",
    "#                 plt.plot(minimas[i][0],minimas[i][1], color='pink', marker='o')\n",
    "#                 plt.scatter(hull[0,0],hull[0,1],color='b')\n",
    "#                 plt.plot(x_c , y_c , 'ro' , markersize = 10)\n",
    "#                 plt.plot([x_c,hull[0,0]],[y_c,hull[0,1]],color='#7FFF00')    \n",
    "#                 plt.plot([x_c,minimas[i][0]],[y_c,minimas[i][1]],color='#FFF68F')\n",
    "#                 show_img(img, 'Valley Points')\n",
    "                \n",
    "    v1 = np.array(sorted(v1, key=lambda x: x[0]))\n",
    "    v2 = np.array(sorted(v2, key=lambda x: x[0]))\n",
    "    v1=v1[0]\n",
    "    v2=v2[0]\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize = (20,10))\n",
    "    plt.plot(v1[0],v1[1], color='orange', marker='o',markersize = 10)\n",
    "    plt.scatter(hull[0,0],hull[0,1],color='c',s=70)\n",
    "    plt.plot(x_c , y_c , 'ro' , markersize = 10)\n",
    "    plt.plot([x_c,hull[0,0]],[y_c,hull[0,1]],color='blue')    \n",
    "    plt.plot([x_c,v1[0]],[y_c,v1[1]],color='m')\n",
    "    show_img(img, 'Valley Point 1')\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize = (20,10))\n",
    "    plt.plot(v2[0],v2[1], color='orange', marker='o',markersize = 10)\n",
    "    plt.scatter(hull[0,0],hull[0,1],color='c',s=70)\n",
    "    plt.plot(x_c , y_c , 'ro' , markersize = 10)\n",
    "    plt.plot([x_c,hull[0,0]],[y_c,hull[0,1]],color='blue')    \n",
    "    plt.plot([x_c,v2[0]],[y_c,v2[1]],color='m')\n",
    "    show_img(img, 'Valley Point 2')\n",
    "    \n",
    "    plt.figure(figsize = (20,10)) \n",
    "    plt.scatter(v1[0],v1[1],color='r',s=70)\n",
    "    plt.scatter(v2[0],v2[1],color='c',s=70)\n",
    "    show_img(img0, 'Valley Points')\n",
    "    \n",
    "    theta = np.arctan2((v2-v1)[1], (v2-v1)[0])*180/np.pi\n",
    "#     print('The rotation of ROI is {:.02f}\\u00b0'.format(theta))\n",
    "    \n",
    "    p_ = int(v2[0]), int(v2[1])\n",
    "    R = cv2.getRotationMatrix2D(tuple(p_), theta, 1)\n",
    "    img_r = cv2.warpAffine(img0, R, (w,h))\n",
    "    v1 = (R[ : , : 2] @ v1 + R[ :, -1]).astype(int)\n",
    "    v2 = (R[ : , : 2] @ v2 + R[ :, -1]).astype(int)\n",
    "    plt.figure(figsize = (20,10))\n",
    "   \n",
    "    plt.plot(v1[0], v1[1], 'ro',markersize = 10)\n",
    "    plt.plot(v2[0], v2[1], 'co',markersize = 10)\n",
    "    plt.plot([v1[0],v2[0]],[v1[1],v2[1]],color='indigo')    \n",
    "    \n",
    "    show_img( img_r , 'Image Rotation' )\n",
    "    \n",
    "    \n",
    "    ux = v1[0]\n",
    "    uy = v1[1] + (v2-v1)[0]//3\n",
    "    lx = v2[0]\n",
    "    ly = v2[1] + 4*(v2-v1)[0]//3\n",
    "    cv2.rectangle(img_r, (lx,ly), (ux,uy), (0,255,0), 5)\n",
    "\n",
    "\n",
    "\n",
    "    roi = img_r[uy:ly , ux:lx]\n",
    "    plt.figure(figsize=(10,10))\n",
    "    show_img(roi,'Location of ROI')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad675293",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "roi1('Hand_images/user_4_5.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc130e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(img):\n",
    "    # We create our gabor filters, and then apply them to our image\n",
    "    \n",
    "    gfilters = create_gaborfilter()\n",
    "    image_gabor = apply_filter(img, gfilters)\n",
    "\n",
    "    #Median Filter\n",
    "    median_filter = cv2.medianBlur(image_gabor,7)\n",
    "\n",
    "    # cv2.cvtColor is applied over the\n",
    "    # image input with applied parameters\n",
    "    # to convert the image in grayscale \n",
    "    gray = cv2.cvtColor(median_filter, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Using an adaptive thresholging of Gaussian.\n",
    "    gaussian_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY, 199, 5)\n",
    "\n",
    "    g_img = cv2.cvtColor(gaussian_thresh, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    \n",
    "    return g_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4560a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71d994",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(preprocessing(roi(input_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3298fb6d",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a31114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5affc7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62628e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating folder \n",
    "POS_PATH = os.path.join('user_4','positive')\n",
    "NEG_PATH = os.path.join('user_4','negative')\n",
    "ANC_PATH = os.path.join('user_4','anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253b2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs('user_4')\n",
    "# # Folders\n",
    "# os.makedirs(POS_PATH)\n",
    "# os.makedirs(NEG_PATH)\n",
    "# os.makedirs(ANC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8ea0be",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i, file in enumerate(os.listdir('Hand_images'), start=1):\n",
    "    if re.match(r'user_4_\\d+.jpg', file) and 0 <= count < 13:\n",
    "        filena = file.split('.')\n",
    "        file_path = (os.path.join('Hand_images', file))\n",
    "        #         print(file_path)\n",
    "        roi_ex = preprocessing(roi(file_path))\n",
    "        cv2.imwrite(os.path.join(ANC_PATH, f'roi_{file}'), roi_ex)\n",
    "        count += 1\n",
    "\n",
    "    elif re.match(r'user_4_\\d+.jpg', file) and 13 <= count < 26:\n",
    "        file_path = (os.path.join('Hand_images', file))\n",
    "        #         print(file)\n",
    "        roi_ex = preprocessing(roi(file_path))\n",
    "        cv2.imwrite(os.path.join(POS_PATH, f'roi_{file}'), roi_ex)\n",
    "        count += 1\n",
    "    else:\n",
    "        file_path = (os.path.join('Hand_images', file))\n",
    "#         print(file)\n",
    "        roi_ex = preprocessing(roi(file_path))\n",
    "        cv2.imwrite(os.path.join(NEG_PATH, f'roi_{file}'), roi_ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79165ded",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# data Augmentation\n",
    "for file in os.listdir(POS_PATH):\n",
    "    if re.match(r'roi_user_\\d_\\d+.jpg', file):\n",
    "        src = cv2.imread(os.path.join(POS_PATH,file))\n",
    "        cc_90 = cv2.rotate(src, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        cv2.imwrite(os.path.join(POS_PATH, f'cc_90{file}'), cc_90)\n",
    "\n",
    "        _180 = cv2.rotate(src, cv2.ROTATE_180)\n",
    "        cv2.imwrite(os.path.join(POS_PATH, f'_180_{file}'), _180)\n",
    "\n",
    "        c_90 = cv2.rotate(src, cv2.ROTATE_90_CLOCKWISE)\n",
    "        cv2.imwrite(os.path.join(POS_PATH, f'c_90{file}'), c_90)\n",
    "\n",
    "for file in os.listdir(NEG_PATH):\n",
    "    if re.match(r'roi_user_\\d_\\d+.jpg', file):\n",
    "        src = cv2.imread(os.path.join(NEG_PATH,file))\n",
    "        cc_90 = cv2.rotate(src, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        cv2.imwrite(os.path.join(NEG_PATH, f'cc_90{file}'), cc_90)\n",
    "\n",
    "        _180 = cv2.rotate(src, cv2.ROTATE_180)\n",
    "        cv2.imwrite(os.path.join(NEG_PATH, f'_180_{file}'), _180)\n",
    "\n",
    "        c_90 = cv2.rotate(src, cv2.ROTATE_90_CLOCKWISE)\n",
    "        cv2.imwrite(os.path.join(NEG_PATH, f'c_90{file}'), c_90)\n",
    "        \n",
    "for file in os.listdir(ANC_PATH):\n",
    "    if re.match(r'roi_user_\\d_\\d+.jpg', file):\n",
    "        src = cv2.imread(os.path.join(ANC_PATH,file))\n",
    "        \n",
    "        cc_90 = cv2.rotate(src, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        cv2.imwrite(os.path.join(ANC_PATH, f'cc_90{file}'), cc_90)\n",
    "\n",
    "        _180 = cv2.rotate(src, cv2.ROTATE_180)\n",
    "        cv2.imwrite(os.path.join(ANC_PATH, f'_180_{file}'), _180)\n",
    "\n",
    "        c_90 = cv2.rotate(src, cv2.ROTATE_90_CLOCKWISE)\n",
    "        cv2.imwrite(os.path.join(ANC_PATH, f'c_90{file}'), c_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1fb453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Creating folder \n",
    "POS_PATH = os.path.join('user_4','positive')\n",
    "NEG_PATH = os.path.join('user_4','negative')\n",
    "ANC_PATH = os.path.join('user_4','anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e1c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(ANC_PATH+\"\\*.jpg\")\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+\"\\*.jpg\")\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+\"\\*.jpg\")\n",
    "# positives = tf.data.Dataset.zip((anchor,positive,tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "# negatives = tf.data.Dataset.zip((anchor,negative,tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "# data_zip = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6910a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(file_path):\n",
    "    \n",
    "    # Read in image from file path\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    # Load in the image \n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    \n",
    "    # Preprocessing steps - resizing the image to be 100x100x3\n",
    "    img = tf.image.resize(img, (128,128))\n",
    "    # Scale image to be between 0 and 1 \n",
    "    img = img / 255.0\n",
    "\n",
    "    # Return image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defc4de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9562def",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rescale(anchor.as_numpy_iterator().next()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b68fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f1e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f7ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return(rescale(input_img), rescale(validation_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0399dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = preprocess_twin(*sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57534b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.hstack((res[0],res[1])))\n",
    "res[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838f798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataloader pipeline\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5f4241",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a271c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a75dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training partition\n",
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)\n",
    "# Testing partition\n",
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.take(round(len(data)*.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d7b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e6679b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828de5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_model(): \n",
    "    inp = Input(shape=(128,128,3), name='input_image')\n",
    "    \n",
    "    # First block\n",
    "    c1 = Conv2D(filters = 64, kernel_size = (6,6), activation='relu', padding = 'same')(inp)\n",
    "    m1 = MaxPooling2D(pool_size = (2,2) , strides = 2 )(c1)\n",
    "    \n",
    "    # Second block\n",
    "    c2 = Conv2D(filters = 128, kernel_size = (4,4), activation='relu', padding = 'same')(m1)\n",
    "    m2 = MaxPooling2D(pool_size = (2,2) , strides = 2 )(c2)\n",
    "    \n",
    "    # Third block \n",
    "    c3 = Conv2D(filters = 256, kernel_size = (3,3), activation='relu' , padding = 'same')(m2)\n",
    "    m3 = MaxPooling2D(pool_size = (2,2) , strides = 2 )(c3)\n",
    "    \n",
    "    # Final embedding block\n",
    "#     c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(m3)\n",
    "    d1 = Dense(512, activation='sigmoid')(f1)\n",
    "    \n",
    "    \n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0beefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf63bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e3eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese L1 Distance class\n",
    "class L1Dist(Layer):\n",
    "    \n",
    "    # Init method - inheritance\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "       \n",
    "    # Magic happens here - similarity calculation\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7602a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model(): \n",
    "    \n",
    "    # Anchor image input in the network\n",
    "    input_image = Input(name='input_img', shape=(128,128,3))\n",
    "    \n",
    "    # Validation image in the network \n",
    "    validation_image = Input(name='validation_img', shape=(128,128,3))\n",
    "    \n",
    "    # Combine siamese distance components\n",
    "    siamese_layer = L1Dist()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
    "    \n",
    "    # Classification layer \n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "    \n",
    "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c8303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = make_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fd6715",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5145221",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(1e-5) # 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecf566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = train_data.as_numpy_iterator()\n",
    "batch_1 = test_batch.next()\n",
    "X = batch_1[:2]\n",
    "y = batch_1[2]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197dc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):   \n",
    "    # Record all of our operations \n",
    "    with tf.GradientTape() as tape:     \n",
    "        # Get anchor and positive/negative image\n",
    "        X = batch[:2]\n",
    "        # Get label\n",
    "        y = batch[2]\n",
    "        \n",
    "        # Forward pass\n",
    "        yhat = siamese_model(X, training=True)\n",
    "        # Calculate loss\n",
    "        loss = binary_cross_loss(y, yhat)\n",
    "    print(loss)\n",
    "        \n",
    "    # Calculate gradients\n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "    \n",
    "    # Calculate updated weights and apply to siamese model\n",
    "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
    "        \n",
    "    # Return loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16906c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, EPOCHS):\n",
    "    # Loop through epochs\n",
    "    # Creating a metric object \n",
    "    r = Recall()\n",
    "    p = Precision()\n",
    "    acc = Accuracy()\n",
    "    recall = []\n",
    "    precision = []\n",
    "    accuracy = []\n",
    "    loss_ = []\n",
    "    genuine=[]\n",
    "    imposter=[]\n",
    "    \n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "#         # Creating a metric object \n",
    "#         r = Recall()\n",
    "#         p = Precision()\n",
    "#         acc = Accuracy()\n",
    "        \n",
    "        # Loop through each batch\n",
    "      \n",
    "        for idx, batch in enumerate(data):\n",
    "            # Run train step here\n",
    "            loss = train_step(batch)\n",
    "            yhat = siamese_model.predict(batch[:2])\n",
    "            \n",
    "            r.update_state(batch[2], yhat)\n",
    "            p.update_state(batch[2], yhat) \n",
    "            acc.update_state(batch[2], [1 if prediction >= 0.5 else 0 for prediction in yhat ]) \n",
    "            [genuine.append(round(float(prediction),4)) if prediction >= 0.5 else imposter.append(round(float(prediction),4)) for prediction in yhat ]            \n",
    "            progbar.update(idx+1)\n",
    "        print(loss.numpy(), r.result().numpy(), p.result().numpy(),acc.result().numpy())\n",
    "        recall.append(r.result().numpy())\n",
    "        precision.append(p.result().numpy())\n",
    "        accuracy.append(acc.result().numpy())\n",
    "        loss_.append(loss.numpy())\n",
    "    return recall , precision , accuracy ,loss_,genuine ,imposter\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589371ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c482eb2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%notify\n",
    "recall , precision , accuracy , loss, genuine ,imposter = train(train_data, EPOCHS=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d260bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of test data\n",
    "test_input, test_val, y_true = test_data.as_numpy_iterator().next()\n",
    "y_hat = siamese_model.predict([test_input, test_val])\n",
    "# Post processing the results \n",
    "[1 if prediction >= 0.5 else 0 for prediction in y_hat ]\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9240c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50e2835",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "style = ['Solarize_Light2', '_classic_test_patch', '_mpl-gallery', '_mpl-gallery-nogrid', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn', 'seaborn-bright', 'seaborn-colorblind', 'seaborn-dark', 'seaborn-dark-palette', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', 'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', 'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'tableau-colorblind10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c3f82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c023ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.style.use('grayscale')\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.plot(loss,label ='Loss',color='k')\n",
    "# plt.title('Figure 1: Training Loss',fontsize=25,y=-.2)\n",
    "plt.xlabel('# EPOCHS',fontsize=18)\n",
    "plt.ylabel('Loss',fontsize=25)\n",
    "plt.legend(loc=1,fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc679691",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('grayscale')\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.plot(precision, label='Precision',color='m')\n",
    "plt.plot(recall , label='Recall',color='g')\n",
    "# plt.title('Figure 2: Precision and Recall for Training Data',fontsize=25,y=-.2)\n",
    "plt.xlabel('# EPOCHS',fontsize=18)\n",
    "plt.ylabel('Precision and Recall',fontsize=20)\n",
    "plt.legend(loc=4,fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('grayscale')\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.plot(accuracy , label ='Accuracy',color='r')\n",
    "# plt.title('Figure 3: Training Accuracy',fontsize=25,y=-.2)\n",
    "plt.xlabel('# EPOCHS',fontsize=18)\n",
    "plt.ylabel('Accuracy',fontsize=20)\n",
    "plt.legend(loc=4,fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1331b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4daeae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d190df85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9ab335",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.distplot(imposter,color = 'purple',label='Imposter Distribution')\n",
    "sns.distplot(genuine,color='orange',label='Genuine Distribution')\n",
    "# plt.title('Figure 4: Distribution of Training samples',fontsize=25,y=-.2)\n",
    "plt.xlabel('Probablities',fontsize=18)\n",
    "plt.ylabel('Density Distribution',fontsize=20)\n",
    "plt.legend(loc=1,fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d0f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data,schuffle):\n",
    "    # Loop through epochs\n",
    "    # Creating a metric object \n",
    "    r = Recall()\n",
    "    p = Precision()\n",
    "    acc = Accuracy()\n",
    "    recall = []\n",
    "    precision = []\n",
    "    accuracy = []\n",
    "    loss_ = []\n",
    "    genuine=[]\n",
    "    imposter=[]\n",
    "    for epoch in range(1, schuffle+1):\n",
    "      \n",
    "        for idx, batch in enumerate(data):\n",
    "                # Run train step here\n",
    "                yhat = siamese_model.predict(batch[:2])\n",
    "                r.update_state(batch[2], yhat)\n",
    "                p.update_state(batch[2], yhat) \n",
    "                acc.update_state(batch[2], [1 if prediction >= 0.5 else 0 for prediction in yhat ]) \n",
    "                [genuine.append(round(float(prediction),10)) if prediction >= 0.5 else imposter.append(round(float(prediction),10)) for prediction in yhat ]            \n",
    "\n",
    "#         print( r.result().numpy(), p.result().numpy(),acc.result().numpy())\n",
    "        recall.append(r.result().numpy())\n",
    "        precision.append(p.result().numpy())\n",
    "        accuracy.append(acc.result().numpy())\n",
    "    return recall , precision , accuracy ,loss_,genuine ,imposter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7476543",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_ , precision_ , accuracy_ , loss_ , genuine_ ,imposter_ = test(test_data,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6847d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use('seaborn-bright')\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.plot(accuracy_ , label ='Accuracy',color='r')\n",
    "plt.title('Figure 6: Testing Accuracy',fontsize=25,y=-.2)\n",
    "plt.xlabel('# EPOCHS',fontsize=18)\n",
    "plt.ylabel('Accuracy',fontsize=20)\n",
    "plt.legend(loc=4,fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd0a524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59890d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-bright')\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.distplot(imposter_,color = 'purple',label='Imposter Distribution')\n",
    "sns.distplot(genuine_,color='g',label='Genuine Distribution')\n",
    "# plt.title('Figure 5: Distribution of Test Data',fontsize=25,y=-.2)\n",
    "plt.xlabel('Probablities',fontsize=18)\n",
    "plt.ylabel('Density Distribution',fontsize=20)\n",
    "plt.legend(loc=1,fontsize=15)\n",
    "plt.xlim([-0.2,1.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4891ab49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
